# An√°lise Comparativa de Verifica√ß√£o de Locutor com k-NN e SVM

Este reposit√≥rio cont√©m o projeto desenvolvido para a disciplina de Introdu√ß√£o √† Intelig√™ncia Artificial, do curso de Bacharelado em Tecnologia da Informa√ß√£o do Instituto Metr√≥pole Digital (IMD/UFRN).

**Aluna:** Ros√¢ngela D'Avilla

## üéØ Objetivos e Aplica√ß√µes

O objetivo central deste projeto √© desenvolver e avaliar um sistema de verifica√ß√£o de locutor. Em vez de identificar quem est√° falando (identifica√ß√£o de locutor), o sistema foca em responder √† seguinte pergunta:

> "Estes dois √°udios pertencem √† mesma pessoa?" (Sim/N√£o)

Para isso, o projeto realiza uma an√°lise comparativa entre dois algoritmos cl√°ssicos de aprendizado de m√°quina, **k-Nearest Neighbors (k-NN)** e **Support Vector Machine (SVM)**, para determinar qual deles oferece o melhor desempenho na tarefa proposta.

A principal aplica√ß√£o de um sistema como este est√° em √°reas **forense e criminal**, onde acontece muitas vezes de precisar saber se a voz que aparece em um √°udio ou v√≠deo √© de determinado acusado/criminoso.

## üìö Dataset Utilizado: Common Voice (Mozilla)

Para treinar e testar os modelos, foi utilizado o dataset **Common Voice Corpus 22.0**, mantido pela Mozilla. Este √© um dataset p√∫blico e colaborativo, com as seguintes caracter√≠sticas:

- **Licen√ßa:** CC-0 (Dom√≠nio P√∫blico)  
- **Formato:** Arquivos de √°udio em `.mp3` acompanhados de metadados em um arquivo `.tsv`  
- **Volume de Dados:** A vers√£o utilizada conta com **185 horas de √°udio validadas**, de **3.759 locutores diferentes**

O dataset apresenta uma diversidade de locutores, embora com um desbalanceamento demogr√°fico not√°vel, com predomin√¢ncia de **locutores masculinos (68%)** e da **faixa et√°ria de 20 a 29 anos (36%)**.

## ü§ñ Arquitetura do Agente e Modelagem

### Representa√ß√£o de Conhecimento

O principal desafio √© transformar um sinal de √°udio em dados que um modelo de IA possa entender. Para isso, utilizamos a t√©cnica de **Coeficientes Cepstrais de Frequ√™ncia Mel (MFCC)**. O MFCC processa o √°udio e o converte em uma matriz num√©rica que funciona como uma "assinatura vocal".

O conhecimento que o agente utiliza para a decis√£o n√£o s√£o os MFCCs brutos, mas sim a **diferen√ßa absoluta** calculada entre as matrizes MFCC de um par de √°udios. Essa diferen√ßa √© o vetor de **features** de entrada para os modelos.

### Algoritmos de IA

Foram implementados e comparados dois agentes baseados em algoritmos de aprendizado supervisionado:

- **k-Nearest Neighbors (k-NN):** Um modelo baseado em inst√¢ncia que classifica um novo dado com base na classe de seus "vizinhos" mais pr√≥ximos.  
  - *Implementa√ß√£o:* `KNeighborsClassifier` da biblioteca **scikit-learn**  
  - *Par√¢metro Principal:* `n_neighbors = 5`

- **Support Vector Machine (SVM):** Um modelo que busca encontrar o melhor hiperplano para separar os dados em diferentes classes.  
  - *Implementa√ß√£o:* `SVC` da biblioteca **scikit-learn**  
  - *Par√¢metro Principal:* `kernel = 'rbf'` (fun√ß√£o de base radial)

### Modelagem PEAS

A tarefa do agente foi modelada utilizando o framework **PEAS** (Performance, Environment, Actuators, Sensors):

- **P (Performance / Desempenho):** Acur√°cia do sistema em classificar corretamente se duas amostras de √°udio s√£o do mesmo locutor ("Sim" / "N√£o"). A **Matriz de Confus√£o** √© usada para uma an√°lise detalhada dos acertos e erros.  
- **E (Environment / Ambiente):** Pares de √°udios reais do dataset Common Voice, que possuem varia√ß√µes de qualidade, ru√≠do de fundo e caracter√≠sticas de diferentes locutores.  
- **A (Actuators / Atuadores):** O sistema processa um par de √°udios e produz uma sa√≠da bin√°ria: `1` se pertencerem ao mesmo locutor ou `0` caso contr√°rio.  
- **S (Sensors / Sensores):** O agente "percebe" o ambiente atrav√©s de arquivos de √°udio brutos (em formato `.mp3`) e, a partir deles, realiza a extra√ß√£o dos coeficientes MFCC.

## üõ†Ô∏è Pipeline do Projeto

O processo de constru√ß√£o do modelo seguiu 4 etapas principais:

1. **Sele√ß√£o de Locutores V√°lidos:**  
   Foram filtrados apenas os locutores que possu√≠am no m√≠nimo 4 clipes de √°udio no dataset. Isso resultou em **93 locutores v√°lidos**.

2. **Cria√ß√£o dos Pares de √Åudios:**  
   - **Pares Positivos (Label = 1):** Dois √°udios distintos do mesmo locutor.  
   - **Pares Negativos (Label = 0):** Um √°udio de um locutor e outro de um locutor diferente, escolhido aleatoriamente.

3. **Pr√©-processamento e Extra√ß√£o de Features:**  
   Para cada par, os **MFCCs** foram extra√≠dos e a **diferen√ßa absoluta** entre eles foi calculada, resultando em um vetor de entrada.

4. **Treinamento e Teste:**  
   O dataset final foi dividido em **80% para treinamento (1004 amostras)** e **20% para teste (252 amostras)**.

## üìä M√©tricas e Desempenho

A performance dos modelos foi avaliada com base na **Acur√°cia** e na an√°lise da **Matriz de Confus√£o**.

### Resultados

| Modelo | Acur√°cia | VN  | FP  | FN  | VP  |
|--------|----------|-----|-----|-----|-----|
| k-NN   | 82.9%    | 157 | 30  | 13  | 52  |
| SVM    | 88.5%    | 176 | 11  | 18  | 47  |

O modelo **SVM** alcan√ßou uma acur√°cia superior (**88.5%**), demonstrando ser mais eficaz para esta tarefa. Ele tamb√©m teve **menos Falsos Positivos** (11 contra 30 do k-NN), ou seja, errou menos ao dizer que dois locutores diferentes eram a mesma pessoa.

## ‚ö†Ô∏è Limita√ß√µes e Dificuldades

### Limita√ß√µes do Projeto e da Arquitetura

- **Representa√ß√£o de Features Simplificada:** A diferen√ßa absoluta entre MFCCs √© uma abordagem simplificada que perde informa√ß√µes temporais.
- **Sensibilidade dos Algoritmos:**  
  - O k-NN depende fortemente da escolha de `k`.  
  - O SVM depende do `kernel` e dos hiperpar√¢metros.  
- **Abordagem Cl√°ssica vs. Moderna:** T√©cnicas mais recentes como **CNNs** em espectrogramas ou **Transformers** podem gerar melhores resultados.

### Dificuldades no Processo

- **Dataset Desbalanceado: A predomin√¢ncia de locutores masculinos e jovens pode ter criado um vi√©s no modelo.
- **Features Simplificadas: A "diferen√ßa absoluta" dos MFCCs perde detalhes temporais da voz.
- **Abordagem Cl√°ssica: Modelos modernos de Deep Learning costumam ter performance superior.

## ‚ú® Sugest√µes de Melhorias

- **Usar PyCaret: Se eu tivesse usado o PyCaret teria comparado mais modelos.
- **Balancear melhor os dados.
- **Talvez tentar tratar os √°udios antes (Redu√ß√£o de ru√≠do, etc...)




Explorar Modelos de Deep Learning: Implementar uma Rede Neural Convolucional (CNN) que opere diretamente sobre os espectrogramas dos √°udios. Essa abordagem permite que o modelo aprenda as features relevantes automaticamente, em vez de depender da extra√ß√£o manual de MFCCs.

Utilizar Arquiteturas State-of-the-Art: Experimentar com modelos pr√©-treinados para verifica√ß√£o de locutor, como os baseados na arquitetura Transformer, que s√£o o estado da arte para tarefas envolvendo dados sequenciais como a voz.
